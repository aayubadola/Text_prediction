{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QAkvD8o2lI-M"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Lehkto_nlI-V"
   },
   "outputs": [],
   "source": [
    "path_to_file='shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YuYivfuLlI-b"
   },
   "outputs": [],
   "source": [
    "text=open(path_to_file,'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjPZfL-FlI-i",
    "outputId": "c86b4e57-b07f-4f4b-f757-a6f4d0308632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3bOj_a4AlI-q"
   },
   "outputs": [],
   "source": [
    "vocab=sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lh8_vvYBlI-w",
    "outputId": "457e01cd-93e1-4032-e175-d73a9aad7e8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXLcwdk1lI-2",
    "outputId": "2942f3ee-71b0-4a45-d032-e51939c5f156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n",
      "(10, '.')\n",
      "(11, '0')\n",
      "(12, '1')\n",
      "(13, '2')\n",
      "(14, '3')\n",
      "(15, '4')\n",
      "(16, '5')\n",
      "(17, '6')\n",
      "(18, '7')\n",
      "(19, '8')\n",
      "(20, '9')\n",
      "(21, ':')\n",
      "(22, ';')\n",
      "(23, '<')\n",
      "(24, '>')\n",
      "(25, '?')\n",
      "(26, 'A')\n",
      "(27, 'B')\n",
      "(28, 'C')\n",
      "(29, 'D')\n",
      "(30, 'E')\n",
      "(31, 'F')\n",
      "(32, 'G')\n",
      "(33, 'H')\n",
      "(34, 'I')\n",
      "(35, 'J')\n",
      "(36, 'K')\n",
      "(37, 'L')\n",
      "(38, 'M')\n",
      "(39, 'N')\n",
      "(40, 'O')\n",
      "(41, 'P')\n",
      "(42, 'Q')\n",
      "(43, 'R')\n",
      "(44, 'S')\n",
      "(45, 'T')\n",
      "(46, 'U')\n",
      "(47, 'V')\n",
      "(48, 'W')\n",
      "(49, 'X')\n",
      "(50, 'Y')\n",
      "(51, 'Z')\n",
      "(52, '[')\n",
      "(53, ']')\n",
      "(54, '_')\n",
      "(55, '`')\n",
      "(56, 'a')\n",
      "(57, 'b')\n",
      "(58, 'c')\n",
      "(59, 'd')\n",
      "(60, 'e')\n",
      "(61, 'f')\n",
      "(62, 'g')\n",
      "(63, 'h')\n",
      "(64, 'i')\n",
      "(65, 'j')\n",
      "(66, 'k')\n",
      "(67, 'l')\n",
      "(68, 'm')\n",
      "(69, 'n')\n",
      "(70, 'o')\n",
      "(71, 'p')\n",
      "(72, 'q')\n",
      "(73, 'r')\n",
      "(74, 's')\n",
      "(75, 't')\n",
      "(76, 'u')\n",
      "(77, 'v')\n",
      "(78, 'w')\n",
      "(79, 'x')\n",
      "(80, 'y')\n",
      "(81, 'z')\n",
      "(82, '|')\n",
      "(83, '}')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TXdvYd92lI-_"
   },
   "outputs": [],
   "source": [
    "char_to_ind={char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-vSggd5lI_I",
    "outputId": "b2244f5c-4985-444e-c780-a41a8958b783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " '(': 6,\n",
       " ')': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '0': 11,\n",
       " '1': 12,\n",
       " '2': 13,\n",
       " '3': 14,\n",
       " '4': 15,\n",
       " '5': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " ':': 21,\n",
       " ';': 22,\n",
       " '<': 23,\n",
       " '>': 24,\n",
       " '?': 25,\n",
       " 'A': 26,\n",
       " 'B': 27,\n",
       " 'C': 28,\n",
       " 'D': 29,\n",
       " 'E': 30,\n",
       " 'F': 31,\n",
       " 'G': 32,\n",
       " 'H': 33,\n",
       " 'I': 34,\n",
       " 'J': 35,\n",
       " 'K': 36,\n",
       " 'L': 37,\n",
       " 'M': 38,\n",
       " 'N': 39,\n",
       " 'O': 40,\n",
       " 'P': 41,\n",
       " 'Q': 42,\n",
       " 'R': 43,\n",
       " 'S': 44,\n",
       " 'T': 45,\n",
       " 'U': 46,\n",
       " 'V': 47,\n",
       " 'W': 48,\n",
       " 'X': 49,\n",
       " 'Y': 50,\n",
       " 'Z': 51,\n",
       " '[': 52,\n",
       " ']': 53,\n",
       " '_': 54,\n",
       " '`': 55,\n",
       " 'a': 56,\n",
       " 'b': 57,\n",
       " 'c': 58,\n",
       " 'd': 59,\n",
       " 'e': 60,\n",
       " 'f': 61,\n",
       " 'g': 62,\n",
       " 'h': 63,\n",
       " 'i': 64,\n",
       " 'j': 65,\n",
       " 'k': 66,\n",
       " 'l': 67,\n",
       " 'm': 68,\n",
       " 'n': 69,\n",
       " 'o': 70,\n",
       " 'p': 71,\n",
       " 'q': 72,\n",
       " 'r': 73,\n",
       " 's': 74,\n",
       " 't': 75,\n",
       " 'u': 76,\n",
       " 'v': 77,\n",
       " 'w': 78,\n",
       " 'x': 79,\n",
       " 'y': 80,\n",
       " 'z': 81,\n",
       " '|': 82,\n",
       " '}': 83}"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MXG9Lbl7lI_Q"
   },
   "outputs": [],
   "source": [
    "int_to_char=np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3C3NiOx9lI_Y"
   },
   "outputs": [],
   "source": [
    "encoded_text=np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuSKxGMVlI_g",
    "outputId": "42463998-1b44-4ed9-830e-ec32b4a44642"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ..., 30, 39, 29])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "KLzvCdt3lI_n",
    "outputId": "4b42c2f1-120a-40aa-f9b0-091bd72bf92e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=text[:500]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEqRt7UulI_w",
    "outputId": "f4ff113b-d061-4a61-8383-7e355834cfae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
       "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
       "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
       "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
       "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
       "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
       "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
       "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
       "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
       "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
       "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
       "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
       "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
       "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
       "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
       "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
       "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
       "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
       "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
       "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
       "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
       "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
       "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
       "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
       "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
       "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
       "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
       "        1, 70, 78, 69,  1, 57, 76])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrKGV3w-lI_7",
    "outputId": "c6a98c42-ab6b-4660-f9bb-c77db1abb9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gUC63_mElJAD"
   },
   "outputs": [],
   "source": [
    "line='From fairest creatures we desire increase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XajwV2_lJAK",
    "outputId": "b152ca0a-b0cf-49d7-f75a-46bbd1168e66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tdvfSnz7lJAS"
   },
   "outputs": [],
   "source": [
    "lines='''\n",
    " From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3YvC5EAlJAd",
    "outputId": "8d6cf953-4ebc-43de-9a0a-a271e5d77bf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "e74eHPyrlJAl"
   },
   "outputs": [],
   "source": [
    "seq_len=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8bLWgo8ClJAu"
   },
   "outputs": [],
   "source": [
    "total_num_seq=len(text)//(seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXiN-nbIlJA2",
    "outputId": "0ed7b8ba-3086-4c5a-8fb4-a98efeb36582"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RnJfpe3FlJA-"
   },
   "outputs": [],
   "source": [
    "char_dataset=tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cq-y4BmIlJBE",
    "outputId": "1bf6dbcc-43a9-4d8b-a641-4480eaedea7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rH_FOk_VlJBN"
   },
   "outputs": [],
   "source": [
    "sequence=char_dataset.batch(seq_len+1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yLm1_0iilJBU"
   },
   "outputs": [],
   "source": [
    "def create_sequence(seq):\n",
    "    input_text=seq[:-1]\n",
    "    target_text=seq[1:]\n",
    "    return input_text,target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CCrazR5blJBb"
   },
   "outputs": [],
   "source": [
    "dataset=sequence.map(create_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9DMzGXFlJBh",
    "outputId": "31851ec8-6014-4764-b999-1cfe740cda69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((120,), (120,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWHKoYFplJBk",
    "outputId": "192e0064-e382-46b5-ff36-ebc5f965d2c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_txt,target_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(''.join(int_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    print(''.join(int_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hidYb8DVlJBo"
   },
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "duhW8xixlJBr"
   },
   "outputs": [],
   "source": [
    "buffer_size=10000\n",
    "dataset=dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2JthPXElJBv",
    "outputId": "9990bbc3-eea4-4875-a56c-3334c268110c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "8Dz4qRgslJBy"
   },
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k36bq7eDlJB0",
    "outputId": "0bf42570-84e2-4326-a15d-9304f21bc1dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "c2-k3HdjlJB2"
   },
   "outputs": [],
   "source": [
    "embed_dim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "kHufRQ9ylJB5"
   },
   "outputs": [],
   "source": [
    "rnn_nuerons=1050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1SmDMRholJB7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "YmsdxGJ4lJCB"
   },
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PgbFR56JlJCD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,GRU,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "WyCfPpnVlJCG"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size,embed_dim,rnn_nuerons,batch_size):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
    "    model.add(GRU(rnn_nuerons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile('adam',loss=sparse_cat_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "9WNKmuLllJCJ"
   },
   "outputs": [],
   "source": [
    "model=create_model(vocab_size=vocab_size,embed_dim=embed_dim,rnn_nuerons=rnn_nuerons,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGlNZqHNlJCM",
    "outputId": "e7a6af03-5eb3-4edd-ed77-d11ea4d57ca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1050)         3515400   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 84)           88284     \n",
      "=================================================================\n",
      "Total params: 3,609,060\n",
      "Trainable params: 3,609,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "UQTQsq5klJCP"
   },
   "outputs": [],
   "source": [
    "for input_example_batch,target_examp in dataset.take(1):\n",
    "    example_batch_prediction=model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "DglFZhM9lJCS"
   },
   "outputs": [],
   "source": [
    "sample_indecis=tf.random.categorical(example_batch_prediction[0],num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "PaC1wmlalJCV"
   },
   "outputs": [],
   "source": [
    "sample_indecis=tf.squeeze(sample_indecis,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ckNBmNAlJCY",
    "outputId": "0d5c133c-1dfc-49f9-e4b6-70ec02bf3f0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75, 36, 31, 26, 63,  5, 80, 77, 23, 31, 28, 70, 47,  6, 31, 61, 82,\n",
       "       52, 57, 70, 57, 36, 66, 40, 58, 43, 53, 25, 33, 15, 14,  6, 19, 62,\n",
       "       82, 28, 68,  0, 45, 28, 30, 25, 24, 50,  1, 57, 64, 33, 14, 74, 47,\n",
       "       75, 59, 21, 20, 12,  8, 39, 51, 40, 79, 55, 54, 11, 35, 83, 24, 77,\n",
       "       18, 11,  0,  2, 71, 18,  6, 79, 35, 30, 67, 58,  4, 82, 42, 32, 16,\n",
       "        4, 46, 64, 22, 53, 66, 58, 25, 36, 20, 50, 51, 18, 53, 16, 80, 18,\n",
       "       74, 50, 11, 38, 44,  7, 57, 79, 75, 39, 24,  7,  1, 24, 27, 78,  7,\n",
       "       79])"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indecis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oa8DjrM7lJCb",
    "outputId": "ef123cba-8112-46b3-cdb1-dfe25a368a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['t', 'K', 'F', 'A', 'h', \"'\", 'y', 'v', '<', 'F', 'C', 'o', 'V',\n",
       "       '(', 'F', 'f', '|', '[', 'b', 'o', 'b', 'K', 'k', 'O', 'c', 'R',\n",
       "       ']', '?', 'H', '4', '3', '(', '8', 'g', '|', 'C', 'm', '\\n', 'T',\n",
       "       'C', 'E', '?', '>', 'Y', ' ', 'b', 'i', 'H', '3', 's', 'V', 't',\n",
       "       'd', ':', '9', '1', ',', 'N', 'Z', 'O', 'x', '`', '_', '0', 'J',\n",
       "       '}', '>', 'v', '7', '0', '\\n', '!', 'p', '7', '(', 'x', 'J', 'E',\n",
       "       'l', 'c', '&', '|', 'Q', 'G', '5', '&', 'U', 'i', ';', ']', 'k',\n",
       "       'c', '?', 'K', '9', 'Y', 'Z', '7', ']', '5', 'y', '7', 's', 'Y',\n",
       "       '0', 'M', 'S', ')', 'b', 'x', 't', 'N', '>', ')', ' ', '>', 'B',\n",
       "       'w', ')', 'x'], dtype='<U1')"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_char[sample_indecis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ZVsFNXR6lJCf"
   },
   "outputs": [],
   "source": [
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmQksTySmGkE",
    "outputId": "ef9f49b4-61fa-4123-e8bc-f23f62a44265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "351/351 [==============================] - 49s 132ms/step - loss: 3.1183\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 51s 141ms/step - loss: 1.8324\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 1.5077\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 1.3652\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 1.2912\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 1.2479\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 1.2168\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 1.1920\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 1.1710\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 1.1524\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 1.1352\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 1.1200\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 1.1068\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 50s 141ms/step - loss: 1.0928\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 51s 141ms/step - loss: 1.0812\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 1.0681\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 1.0573\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 50s 141ms/step - loss: 1.0462\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 1.0374\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 1.0283\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 1.0199\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 1.0124\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 1.0053\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 50s 141ms/step - loss: 0.9984\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9914\n",
      "Epoch 26/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9856\n",
      "Epoch 27/50\n",
      "351/351 [==============================] - 51s 141ms/step - loss: 0.9826\n",
      "Epoch 28/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9781\n",
      "Epoch 29/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9743\n",
      "Epoch 30/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9692\n",
      "Epoch 31/50\n",
      "351/351 [==============================] - 51s 141ms/step - loss: 0.9675\n",
      "Epoch 32/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 0.9654\n",
      "Epoch 33/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9633\n",
      "Epoch 34/50\n",
      "351/351 [==============================] - 51s 141ms/step - loss: 0.9623\n",
      "Epoch 35/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9609\n",
      "Epoch 36/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9614\n",
      "Epoch 37/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9594\n",
      "Epoch 38/50\n",
      "351/351 [==============================] - 51s 141ms/step - loss: 0.9587\n",
      "Epoch 39/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 0.9574\n",
      "Epoch 40/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9585\n",
      "Epoch 41/50\n",
      "351/351 [==============================] - 51s 142ms/step - loss: 0.9583\n",
      "Epoch 42/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9599\n",
      "Epoch 43/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 0.9585\n",
      "Epoch 44/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9578\n",
      "Epoch 45/50\n",
      "351/351 [==============================] - 51s 141ms/step - loss: 0.9612\n",
      "Epoch 46/50\n",
      "351/351 [==============================] - 50s 140ms/step - loss: 0.9639\n",
      "Epoch 47/50\n",
      "351/351 [==============================] - 50s 138ms/step - loss: 0.9634\n",
      "Epoch 48/50\n",
      "351/351 [==============================] - 51s 141ms/step - loss: 0.9625\n",
      "Epoch 49/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9651\n",
      "Epoch 50/50\n",
      "351/351 [==============================] - 50s 139ms/step - loss: 0.9738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f25cbfdb438>"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset ,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ttKkO7qF0F6c"
   },
   "outputs": [],
   "source": [
    "model.save('text_genrator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "x0hecidc0T8d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "CdNLgVvH0ing"
   },
   "outputs": [],
   "source": [
    "model=create_model(vocab_size,embed_dim,rnn_nuerons,batch_size=1)\n",
    "model.load_weights('text_genrator.h5')\n",
    "model.build(tf.TensorShape([1,None]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRFXfipV1QIJ",
    "outputId": "b0830bc0-d293-4be8-c558-e0c8cc588933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1050)           3515400   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 84)             88284     \n",
      "=================================================================\n",
      "Total params: 3,609,060\n",
      "Trainable params: 3,609,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "_f88Tn7A2B3s"
   },
   "outputs": [],
   "source": [
    "def genrate_text(model,start_seed,gen_size=100,temp=0.1):\n",
    "  num_genrate=gen_size\n",
    "  input_eval=[char_to_ind[s] for s in start_seed]\n",
    "  input_eval=tf.expand_dims(input_eval,0)\n",
    "  text_genrated=[]\n",
    "  temperature=temp\n",
    "  model.reset_states()\n",
    "  for i in range(num_genrate):\n",
    "    predictions=model(input_eval)\n",
    "    predictions=tf.squeeze(predictions,0)\n",
    "    predictions=predictions/temperature\n",
    "    predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
    "    input_eval=tf.expand_dims([predicted_id],0)\n",
    "    text_genrated.append(int_to_char[predicted_id])\n",
    "  return(start_seed +''.join(text_genrated))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UniCecDT6PcB",
    "outputId": "9b14072c-2cf4-4fa4-86aa-bc812870af54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUKE. It is the cause of his advantage of his life,\n",
      "    I would not have it so. The strong instruction\n",
      "    That shall be prov'd by the forest looks of thee.\n",
      "    But if thou liest, thou shalt not have the heart.\n",
      "    I will not speak to thee.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Exeunt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SCENE III.\n",
      "The same.\n",
      "\n",
      "Enter Malcolm and a BEADLE with a MASTARD in his hand\n",
      "\n",
      "  SPEED. 'Item: She hath struck thee for thy stars; the sun will be the best\n",
      "    of his state and the rest of the world begin.\n",
      "  SIR TOBY. A good man's son there is no stronger than the same.\n",
      "    What say'st thou, man? What say'st thou still?\n",
      "    I pray you tell me that the strong instruction\n",
      "    Of the steep of his state of war  \n",
      "    That the more fair and dream is to the sea;\n",
      "    And therefore have I seen thee to the state\n",
      "    Than the sea-mark to thee that thou desires  \n",
      "    Than these the father of my lord the King.\n",
      "    O the best portion and a spirit, speaks\n",
      "    The cloudy messenger of state of steel.\n",
      "    The story of the world can do thee good.\n",
      "    I will not change this truth when they desire thee.\n",
      "    But who comes here?\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n"
     ]
    }
   ],
   "source": [
    "print(genrate_text(model,'DUKE',gen_size=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "x3HTa8lf6TN3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rnn_text_predictions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
